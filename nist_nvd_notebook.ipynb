{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Inputs for Network Visualization in D3.js and Gephi\n",
    "## Using NIST National Vulnerabilities Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first import the necessary packages to process the NIST National Vulnerabilities Database (NVD) for 2015. The xml file is available here: [NIST NVD Website](https://nvd.nist.gov/download.cfm#CVE_FEED). The packages used are:\n",
    "    1. re for parsing the xml with regex\n",
    "    2. csv for exporting to comma separated variable file\n",
    "    3. json for exporting to JSON\n",
    "    4. datetime for determining week number of year and day number of week from timestamp\n",
    "    5. (Optional) tqdm for creating a cheap progress bar on an iterable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re, csv, json, datetime\n",
    "from tqdm import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that can parse the NIST NVD xml file and extract the relevant information. More fields are defined and created than is needed for Gephi or the D#.js visualization. The function returns a dictionary by vulnerability key as defined by https://cve.mitre.org/. All additional information is then stored in a dictionary for that particular vulnerability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pull_nvd(fname):\n",
    "    print 'Loading NVD Dataset'\n",
    "    nvd_dict = {}\n",
    "    with open(fname) as f:\n",
    "        for ln in tqdm(f):\n",
    "            if 'entry id=' in ln:\n",
    "                vuln_id = re.search('CVE.\\d\\d\\d\\d.\\d\\d\\d\\d', ln).group(0)\n",
    "                # print '************************%s************************'%vuln_id\n",
    "                nvd_dict[vuln_id] = {}\n",
    "            elif 'cpe-lang:fact-ref name=' in ln:\n",
    "                nvd_dict[vuln_id]['vuln_os'] = []\n",
    "                nvd_dict[vuln_id]['vuln_os_plat'] = []\n",
    "                vuln_os = re.search('\\\".*\\\"', ln).group(0)[8:-1]\n",
    "                vuln_os_plat = re.split('[:\\\"]', ln)\n",
    "                # print '--->%s'%vuln_os\n",
    "                nvd_dict[vuln_id]['vuln_os'].append(re.sub('_',' ',vuln_os_plat[4]))\n",
    "                nvd_dict[vuln_id]['vuln_os_plat'].append(re.sub('_',' ',vuln_os_plat[4])+' '+re.sub('_',' ',vuln_os_plat[5]))\n",
    "            elif '<vuln:published-datetime>' in ln:\n",
    "                vuln_date = re.search('2015.*<', ln).group(0)[:-1]\n",
    "                date = [int(vuln_date[0:4]),int(vuln_date[5:7]),int(vuln_date[8:10])]\n",
    "                date_num = datetime.date(date[0],date[1],date[2]).isocalendar()\n",
    "                # print '    --->%s'%vuln_date\n",
    "                nvd_dict[vuln_id]['vuln_date'] = date_num\n",
    "            elif '<cvss:score>' in ln:\n",
    "                vuln_score = re.search('\\d?\\d.\\d', ln).group(0)\n",
    "                # print '    --->%s'%vuln_score\n",
    "                nvd_dict[vuln_id]['vuln_score'] = vuln_score\n",
    "            elif '<cvss:access-vector>' in ln:\n",
    "                vuln_vector = re.search('>.*<', ln).group(0)[1:-1]\n",
    "                # print '    --->%s'%vuln_vector\n",
    "                nvd_dict[vuln_id]['vuln_vector'] = vuln_vector\n",
    "            elif '<cvss:access-complexity>' in ln:\n",
    "                vuln_compl = re.search('>.*<', ln).group(0)[1:-1]\n",
    "                # print '    --->%s'%vuln_compl\n",
    "                nvd_dict[vuln_id]['vuln_compl'] = vuln_compl\n",
    "            elif '<cvss:authentication>' in ln:\n",
    "                vuln_auth = re.search('>.*<', ln).group(0)[1:-1]\n",
    "                # print '    --->%s'%vuln_auth\n",
    "                nvd_dict[vuln_id]['vuln_auth'] = vuln_auth\n",
    "            elif '<cvss:confidentiality-impact>' in ln:\n",
    "                vuln_confid = re.search('>.*<', ln).group(0)[1:-1]\n",
    "                # print '    --->%s'%vuln_confid\n",
    "                nvd_dict[vuln_id]['vuln_confid'] = vuln_confid\n",
    "            elif '<cvss:integrity-impact>' in ln:\n",
    "                vuln_integ = re.search('>.*<', ln).group(0)[1:-1]\n",
    "                # print '    --->%s'%vuln_integ\n",
    "                nvd_dict[vuln_id]['vuln_integ'] = vuln_integ\n",
    "            elif '<cvss:availability-impact>' in ln:\n",
    "                vuln_avail = re.search('>.*<', ln).group(0)[1:-1]\n",
    "                # print '    --->%s'%vuln_avail\n",
    "                nvd_dict[vuln_id]['vuln_avail'] = vuln_avail\n",
    "            elif 'vuln:reference href=' in ln:\n",
    "                vuln_link = re.search('href=.*\\\"', ln).group(0)[6:-1]\n",
    "                # print '    --->%s'%vuln_link\n",
    "                nvd_dict[vuln_id]['vuln_link'] = vuln_link\n",
    "            elif '<vuln:summary>' in ln:\n",
    "                vuln_summ = re.search('>.*<', ln).group(0)[1:-1]\n",
    "                # print '    --->%s'%vuln_summ\n",
    "                nvd_dict[vuln_id]['vuln_summ'] = vuln_summ\n",
    "            elif '<vuln:source>' in ln:\n",
    "                vuln_source = re.search('>.*<', ln).group(0)[1:-1]\n",
    "                # print '    --->%s'%vuln_summ\n",
    "                nvd_dict[vuln_id]['vuln_source'] = vuln_source\n",
    "    return(nvd_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the defined function on the xml file extracted to the working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading NVD Dataset\n"
     ]
    }
   ],
   "source": [
    "nvd = pull_nvd('./nvdcve-2.0-2015.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a timeline for 2015 so far by count both the unweighted instances and the weighted totals given the CVE Score provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create timeline of 2015\n",
    "nvd_timeline = [[],[]]\n",
    "for cve in nvd.keys():\n",
    "    if 'vuln_score' in nvd[cve].keys():\n",
    "        weightedme = {'Method':'Weighted', 'Date':nvd[cve]['vuln_datetime'], 'Value':float(nvd[cve]['vuln_score'])}\n",
    "        countme = {'Method':'Count', 'Date':nvd[cve]['vuln_datetime'], 'Value':1}\n",
    "        if nvd[cve]['vuln_datetime'] not in [ x['Date'] for x in nvd_timeline[0] ]:\n",
    "            nvd_timeline[0].append(weightedme)\n",
    "            nvd_timeline[1].append(countme)\n",
    "        else:\n",
    "            for i, day in enumerate(nvd_timeline[0]):\n",
    "                if nvd[cve]['vuln_datetime'] in day['Date'] and day['Method'] == 'Weighted':\n",
    "                    nvd_timeline[0][i]['Value'] += float(nvd[cve]['vuln_score'])\n",
    "                elif nvd[cve]['vuln_datetime'] in day['Date'] and day['Method'] == 'Count':\n",
    "                    nvd_timeline[1][i]['Value'] += 1\n",
    "\n",
    "# Export to json\n",
    "with open('./nvd_timeline.json', 'wb') as f:\n",
    "    json.dump(nvd_timeline, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the parsed dictionary, we create a dictionary of nodes and edges with the additional week number, day number, and threat score loaded. Then given the dictionary, export to JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create Node-Edge JSON\n",
    "nvd_json = {'nodes':[],'links':[]}\n",
    "for cve in nvd.keys():\n",
    "    if 'vuln_os' in nvd[cve].keys():\n",
    "        append_vuln = {'name':cve, 'group':nvd[cve]['vuln_date'][2], 'week':nvd[cve]['vuln_date'][1], 'threat':float(nvd[cve]['vuln_score']), 'type':1}\n",
    "        nvd_json['nodes'].append(append_vuln)\n",
    "        for os in nvd[cve]['vuln_os']:\n",
    "            append_plat = {'name':os, 'group':nvd[cve]['vuln_date'][2], 'week':nvd[cve]['vuln_date'][1], 'threat':0, 'type':0}\n",
    "            if append_plat not in nvd_json['nodes']:\n",
    "                nvd_json['nodes'].append(append_plat)\n",
    "            nvd_json['links'].append({'source':cve, 'target':os, 'group':nvd[cve]['vuln_date'][2], 'week':nvd[cve]['vuln_date'][1], 'threat':float(nvd[cve]['vuln_score'])})\n",
    "\n",
    "# Export to json\n",
    "with open('./nvd.json', 'wb') as f:\n",
    "    json.dump(nvd_json, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build inputs for Gephi. Gephi requires an edge list and (optionally) a node list (if unconnected nodes exist). We create list arrays with header filled in. Then populate each row with either the edge or node. Then write both files to csv files in working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build exact edge list\n",
    "nvd_edge = [['source','target','value']]\n",
    "for cve in nvd.keys():\n",
    "    if 'vuln_score' in nvd[cve].keys():\n",
    "        threat = nvd[cve]['vuln_score']\n",
    "    else:\n",
    "        threat = 0.0\n",
    "    if 'vuln_os_plat' in nvd[cve].keys():\n",
    "        cve_type = (nvd[cve]['vuln_vector'], nvd[cve]['vuln_compl'], nvd[cve]['vuln_auth'], nvd[cve]['vuln_confid'], nvd[cve]['vuln_integ'])\n",
    "        for plat in nvd[cve]['vuln_os_plat']:\n",
    "            appendme = [cve_type, plat, threat]\n",
    "            if appendme not in nvd_edge:\n",
    "                nvd_edge.append(appendme)\n",
    "\n",
    "# # Build exact node list\n",
    "nvd_node = [['id','value','type']]\n",
    "for row in nvd_edge:\n",
    "    append_vuln = [row[0],row[2],0]\n",
    "    append_targ = [row[1],0.0,1]\n",
    "    if append_vuln not in nvd_node:\n",
    "        nvd_node.append(append_vuln)\n",
    "    if append_targ not in nvd_node:\n",
    "        nvd_node.append(append_targ)\n",
    "\n",
    "# Export to CSV for Gephi\n",
    "with open('./nvd_edge.csv', 'wb') as csvfile:\n",
    "    writeme = csv.writer(csvfile, delimiter=',')\n",
    "    writeme.writerows(nvd_edge)\n",
    "\n",
    "with open('./nvd_node.csv', 'wb') as csvfile:\n",
    "    writeme = csv.writer(csvfile, delimiter=',')\n",
    "    writeme.writerows(nvd_node)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
